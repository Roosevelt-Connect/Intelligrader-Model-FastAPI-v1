fastapi==0.104.1
uvicorn[standard]==0.24.0
llama-cpp-python==0.2.90
slowapi==0.1.9
